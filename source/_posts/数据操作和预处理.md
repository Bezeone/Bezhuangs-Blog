---
title: 数据操作和数据预处理
date: 2022-03-13
tags: [PyTorch, Pandas]
categories: 机器学习
references:
  - title: 动手学深度学习
    url: https://zh-v2.d2l.ai/index.html
---

> 要学习深度学习，首先需要先掌握一些基本技能。 所有机器学习方法都涉及从数据中提取信息。 因此，动手学深度学习 v2 课程在第二章的一开始先教授了一些关于数据的实用技能，包括存储、操作和预处理数据，作为预备知识的内容。以下为学习 Dive to Deep Learning（d2l） 课程第二章数据操作 + 数据预处理所记笔记，可供参考。

<!--more-->

### 数据操作

- 为了能够完成各种数据操作，我们需要某种方法来存储和操作数据
- 通常，我们需要做两件重要的事：获取数据和将数据读入计算机后对其进行处理
- 如果没有某种方法来存储数据，那么获取数据是没有意义的

#### n 维数组

- 深度学习存储和操作数据的主要接口是张量（n维数组）。它提供了各种功能，包括基本数学运算、广播、索引、切片、内存节省和转换其他Python对象

- n 维数组，也称为张量（tensor）

- 深度学习框架的张量类（在MXNet中为`ndarray`， 在PyTorch和TensorFlow中为`Tensor`）与Numpy的`ndarray`类似

- 但深度学习框架又比Numpy的`ndarray`多一些重要功能： 首先，GPU 很好地支持加速计算，而 NumPy 仅支持CPU计算； 其次，张量类支持自动微分。 这些功能使得张量类更适合深度学习

- 张量表示由一个数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）

- 可以使用`arange`创建一个行向量`x`。 这个行向量包含从0开始的前12个整数，它们被默认创建为浮点数。 张量中的每个值都称为张量的元素（element）

  ```python
  import torch
  x = torch.arange(12)
  x # tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
  ```

- 可以通过张量的`shape`属性来访问张量（沿每个轴的长度）的形状

  ```python
  x.shape  # torch.Size([12])
  ```

- 如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）

  ```python
  x.numel() # 12
  ```

- 要想改变一个张量的形状而不改变元素数量和元素值，可以调用`reshape`函数

  ```python
  X = x.reshape(3, 4)  # 张量x从形状为（12,）的行向量转换为形状为（3,4）的矩阵
  X # tensor([[ 0,  1,  2,  3],
    #       [ 4,  5,  6,  7],
    #       [ 8,  9, 10, 11]])
  ```

  - 我们可以通过`-1`来调用此自动计算出维度的功能。 即我们可以用`x.reshape(-1,4)`或`x.reshape(3,-1)`来取代`x.reshape(3,4)`

- 使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵

  ```python
  torch.zeros((2, 3, 4))  # tensor([[[0., 0., 0., 0.],
                          #   			[0., 0., 0., 0.],
        								  #  				[0., 0., 0., 0.]],
        								  # 				[[0., 0., 0., 0.],
       								    #  				[0., 0., 0., 0.],
       								    # 				[0., 0., 0., 0.]]])
  torch.ones((2, 3, 4))  # 一个形状为(2,3,4)的张量，其中所有元素都设置为1
  torch.randn(3, 4)  # 一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样
  ```

- 通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。 在这里，最外层的列表对应于轴0，内层的列表对应于轴1

  ```python
  torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])  
  ```

#### 运算符

- 在这些数据上执行数学运算，其中最简单且最有用的操作是按元素（elementwise）运算。 它们将标准标量运算符应用于数组的每个元素。

- 对于将两个数组作为输入的函数，按元素运算将二元运算符应用于两个数组中的每对位置对应的元素。 我们可以基于任何从标量到标量的函数来创建按元素函数

- 对于任意具有相同形状的张量，常见的标准算术运算符（`+`、`-`、`\*`、`/`和`**`）都可以被升级为按元素运算。 我们可以在同一形状的任意两个张量上调用按元素操作

  ```python
  x = torch.tensor([1.0, 2, 4, 8])
  y = torch.tensor([2, 2, 2, 2])
  x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算
  ```

- 按元素方式可以应用更多的计算，包括像求幂这样的一元运算符

  ```python
  torch.exp(x)
  ```

- 除了按元素计算外，我们还可以执行线性代数运算，包括向量点积和矩阵乘法。

- 也可以把多个张量连结（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。 我们只需要提供张量列表，并给出沿哪个轴连结

  ```python
  X = torch.arange(12, dtype=torch.float32).reshape((3,4))
  Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
  torch.cat((X, Y), dim=0) # 沿行（轴-0，形状的第一个元素）连结两个矩阵
  torch.cat((X, Y), dim=1) # 按列（轴-1，形状的第二个元素）连结两个矩阵
  ```

  - 第一个输出张量的轴 -0 长度（6）是两个输入张量轴 -0 长度的总和（3+3）； 第二个输出张量的轴 -1 长度（8）是两个输入张量轴 -1 长度的总和（4+4）

  - 通过逻辑运算符构建二元张量： 对于每个位置，如果`X`和`Y`在该位置相等，则新张量中相应项的值为1。 这意味着逻辑语句`X == Y`在该位置处为真，否则该位置为0

    ```python
    X == Y # tensor([[False,  True, False,  True],
           # 				[False, False, False, False],
           # 				[False, False, False, False]])
    ```

  - 对张量中的所有元素进行求和，会产生一个单元素张量

    ```python
    X.sum() # tensor(66.)
    ```

#### 广播机制

- 即使形状不同，我们仍然可以通过调用广播机制（broadcasting mechanism）来执行按元素操作

- 首先，通过适当复制元素来扩展一个或两个数组， 以便在转换之后，两个张量具有相同的形状。 其次，对生成的数组执行按元素操作。在大多数情况下，我们将沿着数组中长度为1的轴进行广播

  ```python
  a = torch.arange(3).reshape((3, 1))
  b = torch.arange(2).reshape((1, 2))
  a, b # (tensor([[0],
       #    			[1],
       #    			[2]]),
       #  tensor([[0, 1]]))
  ```

- 由于`a`和`b`分别是3×1和1×2矩阵，如果让它们相加，它们的形状不匹配。 我们将两个矩阵广播为一个更大的3×2矩阵，如下所示：矩阵`a`将复制列， 矩阵`b`将复制行，然后再按元素相加

  ```python
  a + b # tensor([[0, 1],
        #  			[1, 2],
        #  			[2, 3]])
  ```

#### 索引和切片

- 就像在任何其他Python数组中一样，张量中的元素可以通过索引访问。

- 与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是-1； 可以指定范围以包含第一个元素和最后一个之前的元素

  ```python
  X[-1], X[1:3] # (tensor([ 8.,  9., 10., 11.]),
                # tensor([[ 4.,  5.,  6.,  7.],
                #         [ 8.,  9., 10., 11.]]))
  ```

- 除读取外，我们还可以通过指定索引来将元素写入矩阵

  ```python
  X[1, 2] = 9 # 将第二行第三列元素改为 9
  ```

- 为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值，例如，`[0:2, :]`访问第1行和第2行，其中 “:” 代表沿轴1（列）的所有元素

  ```python
  X[0:2, :] = 12 # tensor([[12., 12., 12., 12.],
                 #         [12., 12., 12., 12.],
                 #         [ 8.,  9., 10., 11.]])
  ```

#### 节省内存

- 运行一些操作可能会导致为新结果分配内存。 例如，如果我们用`Y = X + Y`，我们将取消引用`Y`指向的张量，而是指向新分配的内存处的张量

  ```python
  before = id(Y)
  Y = Y + X
  id(Y) == before  # False
  ```

- 执行原地操作非常简单。 我们可以使用切片表示法将操作的结果分配给先前分配的数组，例如`Y[:] = <expression>`

  ```python
  Z = torch.zeros_like(Y) # 创建一个新的矩阵Z，其形状与另一个Y相同， 使用zeros_like来分配一个全 0 的块
  print('id(Z):', id(Z))
  Z[:] = X + Y
  print('id(Z):', id(Z))  # id一样
  ```

  - 如果在后续计算中没有重复使用`X`， 我们也可以使用`X[:] = X + Y`或`X += Y`来减少操作的内存开销

#### 转换为其他Python对象

- 将深度学习框架定义的张量[转换为NumPy张量（`ndarray`）很容易，反之也同样容易

- torch张量和numpy数组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量

  ```python
  A = X.numpy()
  B = torch.tensor(A)
  type(A), type(B) # (numpy.ndarray, torch.Tensor)
  ```

- 要(将大小为1的张量转换为Python标量，我们可以调用`item`函数或Python的内置函数

  ```python
  a = torch.tensor([3.5])
  a, a.item(), float(a), int(a)
  # (tensor([3.5000]), 3.5, 3.5, 3)
  ```

### 数据预处理

- 为了能用深度学习来解决现实世界的问题，我们经常从预处理原始数据开始， 而不是从那些准备好的张量格式数据开始
- 在Python中常用的数据分析工具中，我们通常使用`pandas`软件包。 像庞大的Python生态系统中的许多其他扩展包一样，`pandas`可以与张量兼容

#### 读取数据集

- 首先创建一个人工数据集，并存储在CSV（逗号分隔值文件) `../data/house_tiny.csv`中。 以其他格式存储的数据也可以通过类似的方式进行处理

  ```python
  import os
  
  os.makedirs(os.path.join('..', 'data'), exist_ok=True)
  data_file = os.path.join('..', 'data', 'house_tiny.csv')
  with open(data_file, 'w') as f:
      f.write('NumRooms,Alley,Price\n')  # 列名
      f.write('NA,Pave,127500\n')  # 每行表示一个数据样本
      f.write('2,NA,106000\n')
      f.write('4,NA,178100\n')
      f.write('NA,NA,140000\n')
  ```

- 要从创建的CSV文件中加载原始数据集，我们导入`pandas`包并调用`read_csv`函数

  ```python
  import pandas as pd
  
  data = pd.read_csv(data_file)
  print(data)
  ```

  - 该数据集有四行三列。其中每行描述了房间数量（“NumRooms”）、巷子类型（“Alley”）和房屋价格（“Price”）

#### 处理缺失值

- “NaN”项代表缺失值

- 为了处理缺失的数据，典型的方法包括插值法和删除法，其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值

- 插值法：通过位置索引`iloc`，将`data`分成`inputs`和`outputs`， 其中前者为`data`的前两列，而后者为`data`的最后一列

  - 对于`inputs`中缺少的数值，我们用同一列的均值替换“NaN”项

  ```python
  inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
  inputs = inputs.fillna(inputs.mean())
  print(inputs)
  ```

- 对于`inputs`中的类别值或离散值，我们将“NaN”视为一个类别

  ```python
  inputs = pd.get_dummies(inputs, dummy_na=True)
  print(inputs)
  ```

#### 转换为张量格式

- 现在`inputs`和`outputs`中的所有条目都是数值类型，它们可以转换为张量格式

- 当数据采用张量格式后，可以通过张量函数来进一步操作

  ```python
  import torch
  X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)
  X, y
  ```

  
